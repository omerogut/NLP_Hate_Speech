{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "\n",
    "X_train, X_test, y_train, y_test, label_dict = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Dropout # type: ignore\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "def build_ann(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "evaluate_model(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_resampled, y_resampled)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    'CountVectorizer': CountVectorizer(ngram_range=(1, 2)),\n",
    "    'TfidfVectorizer': TfidfVectorizer(ngram_range=(1, 2))\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, vectorizer in vectorizers.items():\n",
    "    print(f\"Using {name}\")\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    under_sampler = RandomUnderSampler(random_state=42)\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    \n",
    "    resampling_methods = { \n",
    "        'Original': (X_train_vec, y_train),\n",
    "        'SMOTE': smote.fit_resample(X_train_vec, y_train),\n",
    "        'Undersample': under_sampler.fit_resample(X_train_vec, y_train),\n",
    "        'SMOTE+Tomek': smote_tomek.fit_resample(X_train_vec, y_train)\n",
    "    }\n",
    "    \n",
    "    classifiers = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "        'LightGBM': LGBMClassifier(random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    for method_name, (X_resampled, y_resampled) in resampling_methods.items():\n",
    "        print(f\"Resampling: {method_name}\")\n",
    "        for clf_name, clf in classifiers.items():\n",
    "            print(f\"Training: {clf_name}\")\n",
    "            if clf_name == 'LightGBM':\n",
    "                X_resampled = csr_matrix(X_resampled.astype('float32'))\n",
    "                X_test_vec = csr_matrix(X_test_vec.astype('float32'))\n",
    "\n",
    "            clf.fit(X_resampled, y_resampled)\n",
    "            y_pred = clf.predict(X_test_vec)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            results[(name, method_name, clf_name)] = report\n",
    "\n",
    "def build_ann(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "X_train_vec = vectorizers['TfidfVectorizer'].fit_transform(X_train)\n",
    "X_test_vec = vectorizers['TfidfVectorizer'].transform(X_test)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "ann = build_ann(X_resampled.shape[1])\n",
    "history = ann.fit(X_resampled.toarray(), y_resampled, validation_split=0.2, epochs=10, batch_size=32)\n",
    "\n",
    "y_pred_ann = (ann.predict(X_test_vec.toarray()) > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_ann))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
